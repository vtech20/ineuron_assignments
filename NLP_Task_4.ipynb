{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzU9Sd9o4pBk",
        "outputId": "4dc96e8d-5154-409b-b317-bc70f6a84492"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary:\n",
            "[citation needed]\n",
            "\n",
            "The Cholas came to prominence once more through the rise of the Medieval Chola monarch Vijayalaya (841–878 CE) in about 850 CE. [citation needed] [9][10] During the first decade of the eleventh century, the Chola king Raja Raja Chola I (985–1014) constructed the Brihadeeswarar Temple at Thanjavur.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.cluster.util import cosine_distance\n",
        "import numpy as np\n",
        "\n",
        "# Function to read the text file\n",
        "def read_text_file(file_path):\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        text = file.read()\n",
        "    return text\n",
        "\n",
        "# Function to preprocess the text\n",
        "def preprocess_text(text):\n",
        "    # Tokenize the text into sentences and words\n",
        "    sentences = sent_tokenize(text)\n",
        "    words = [word_tokenize(sentence) for sentence in sentences]\n",
        "\n",
        "    # Remove stopwords and punctuation\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    words = [[word.lower() for word in sentence if word.lower() not in stop_words and word.isalnum()] for sentence in words]\n",
        "\n",
        "    return sentences, words\n",
        "\n",
        "# Function to calculate sentence similarity using cosine distance\n",
        "def sentence_similarity(sent1, sent2):\n",
        "    sent1 = [word.lower() for word in sent1]\n",
        "    sent2 = [word.lower() for word in sent2]\n",
        "\n",
        "    all_words = list(set(sent1 + sent2))\n",
        "\n",
        "    vector1 = [0] * len(all_words)\n",
        "    vector2 = [0] * len(all_words)\n",
        "\n",
        "    for word in sent1:\n",
        "        vector1[all_words.index(word)] += 1\n",
        "\n",
        "    for word in sent2:\n",
        "        vector2[all_words.index(word)] += 1\n",
        "\n",
        "    return 1 - cosine_distance(vector1, vector2)\n",
        "\n",
        "# Function to create a similarity matrix\n",
        "def create_similarity_matrix(sentences):\n",
        "    similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
        "\n",
        "    for i in range(len(sentences)):\n",
        "        for j in range(len(sentences)):\n",
        "            if i != j:\n",
        "                similarity_matrix[i][j] = sentence_similarity(sentences[i], sentences[j])\n",
        "\n",
        "    return similarity_matrix\n",
        "\n",
        "# Function to generate the summary\n",
        "def generate_summary(text, num_sentences=3):\n",
        "    # Preprocess the text\n",
        "    sentences, words = preprocess_text(text)\n",
        "\n",
        "    # Create similarity matrix\n",
        "    similarity_matrix = create_similarity_matrix(words)\n",
        "\n",
        "    # PageRank algorithm\n",
        "    scores = np.array([1.0] * len(sentences))\n",
        "    damping_factor = 0.85\n",
        "    epsilon = 0.001\n",
        "    prev_scores = np.ones(len(sentences))\n",
        "\n",
        "    while np.sum(np.abs(scores - prev_scores)) > epsilon:\n",
        "        prev_scores = scores.copy()\n",
        "        for i in range(len(sentences)):\n",
        "            summation = np.sum(similarity_matrix[:, i] * prev_scores)\n",
        "            scores[i] = (1 - damping_factor) + damping_factor * summation\n",
        "\n",
        "    # Sort the sentences by score\n",
        "    ranked_sentences = [sentence for _, sentence in sorted(zip(scores, sentences), reverse=True)]\n",
        "\n",
        "    # Select top sentences as summary\n",
        "    summary = \" \".join(ranked_sentences[:num_sentences])\n",
        "\n",
        "    return summary\n",
        "\n",
        "# File path of the input text file\n",
        "file_path = \"/content/sample.txt\"\n",
        "\n",
        "# Read the text file\n",
        "text = read_text_file(file_path)\n",
        "\n",
        "# Generate the summary\n",
        "summary = generate_summary(text)\n",
        "\n",
        "# Print the summary\n",
        "print(\"Summary:\")\n",
        "print(summary)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YK2Yb1mk8qjq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}